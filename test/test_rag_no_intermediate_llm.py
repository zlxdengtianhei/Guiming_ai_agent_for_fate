"""
æµ‹è¯•ä¿®æ”¹åçš„RAGæµç¨‹ï¼šä¸ä½¿ç”¨ä¸­é—´LLMè°ƒç”¨ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹chunks
è®°å½•æ‰€æœ‰RAGæŸ¥è¯¢ã€chunksæ”¶é›†å’Œå»é‡è¿‡ç¨‹
"""
import asyncio
import sys
import json
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ backendç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
backend_dir = project_root / "backend"
sys.path.insert(0, str(backend_dir))

from app.services.tarot.reading_service import ReadingService
from app.models.schemas import UserProfileCreate
from app.core.database import get_supabase_service


async def test_rag_no_intermediate_llm():
    """æµ‹è¯•ä¿®æ”¹åçš„RAGæµç¨‹ï¼šä¸ä½¿ç”¨ä¸­é—´LLMè°ƒç”¨"""
    print("\n" + "="*80)
    print("æµ‹è¯•ï¼šRAGæµç¨‹ä¼˜åŒ–ï¼ˆä¸ä½¿ç”¨ä¸­é—´LLMè°ƒç”¨ï¼‰")
    print("="*80)
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    service = ReadingService()
    supabase = get_supabase_service()
    
    # åˆ›å»ºæµ‹è¯•ç”¨æˆ·ä¿¡æ¯
    user_profile = UserProfileCreate(
        age=28,
        gender="female",
        zodiac_sign="Leo",
        appearance_type="wands",
        personality_type="wands",
        preferred_source="pkt"
    )
    
    question = "æˆ‘ä¸‹ä¸ªæœˆè¿åŠ¿å¦‚ä½•"
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # è®°å½•æ‰€æœ‰æ­¥éª¤çš„æ•°æ®
    test_log = {
        "test_timestamp": datetime.now().isoformat(),
        "test_type": "rag_no_intermediate_llm",
        "question": question,
        "user_profile": user_profile.model_dump(),
        "steps": [],
        "reading_id": None,
        "final_result": None,
        "rag_analysis": {
            "total_queries": 0,
            "total_chunks_before_dedup": 0,
            "total_chunks_after_dedup": 0,
            "deduplication_rate": 0.0,
            "chunks_by_source": {},
            "chunks_by_query_type": {}
        },
        "total_time_ms": 0,
        "errors": []
    }
    
    try:
        print(f"\né—®é¢˜: {question}")
        print(f"ç”¨æˆ·ä¿¡æ¯: {user_profile.model_dump()}")
        print("\nå¼€å§‹å åœæµç¨‹...")
        
        # è°ƒç”¨å åœæœåŠ¡
        result = await service.create_reading(
            question=question,
            user_id=None,
            user_selected_spread=None,
            user_profile=user_profile,
            preferred_source="pkt"
        )
        
        reading_id = result.get('reading_id')
        test_log['reading_id'] = reading_id
        
        # è®°å½•æœ€ç»ˆç»“æœ
        test_log['final_result'] = {
            'reading_id': reading_id,
            'question': result.get('question'),
            'spread_type': result.get('spread_type'),
            'cards_count': len(result.get('cards', [])),
            'interpretation_summary': result.get('interpretation', {}).get('overall_summary', '')[:300] if result.get('interpretation') else None,
            'metadata': result.get('metadata')
        }
        
        # ä»æ•°æ®åº“è·å–æ‰€æœ‰è¿‡ç¨‹æ•°æ®
        print("\nä»æ•°æ®åº“è·å–å åœè¿‡ç¨‹æ•°æ®...")
        process_data_result = supabase.table('reading_process_data').select('*').eq('reading_id', reading_id).order('step_order').execute()
        
        if process_data_result.data:
            print(f"æ‰¾åˆ° {len(process_data_result.data)} æ¡è¿‡ç¨‹æ•°æ®è®°å½•")
            
            for step_data in process_data_result.data:
                step_log = {
                    'step_name': step_data.get('step_name'),
                    'step_order': step_data.get('step_order'),
                    'input_data': step_data.get('input_data'),
                    'output_data': step_data.get('output_data'),
                    'prompt_type': step_data.get('prompt_type'),
                    'prompt_content': step_data.get('prompt_content'),
                    'rag_queries': step_data.get('rag_queries'),
                    'model_used': step_data.get('model_used'),
                    'processing_time_ms': step_data.get('processing_time_ms'),
                    'created_at': step_data.get('created_at')
                }
                test_log['steps'].append(step_log)
                
                # åˆ†æRAGæ£€ç´¢æ­¥éª¤
                if step_data.get('step_name') == 'rag_retrieval':
                    output_data = step_data.get('output_data', {})
                    total_before = output_data.get('total_chunks_before_dedup', 0)
                    total_after = output_data.get('total_chunks_after_dedup', 0)
                    
                    test_log['rag_analysis']['total_chunks_before_dedup'] = total_before
                    test_log['rag_analysis']['total_chunks_after_dedup'] = total_after
                    
                    if total_before > 0:
                        dedup_rate = (1 - total_after / total_before) * 100
                        test_log['rag_analysis']['deduplication_rate'] = dedup_rate
                    
                    # ç»Ÿè®¡RAGæŸ¥è¯¢
                    rag_queries = step_data.get('rag_queries', [])
                    test_log['rag_analysis']['total_queries'] = len(rag_queries)
                    
                    # ç»Ÿè®¡chunksæŒ‰æ¥æºåˆ†å¸ƒ
                    card_info = output_data.get('card_information', {})
                    spread_method = output_data.get('spread_method', {})
                    card_relationships = output_data.get('card_relationships', {})
                    
                    chunks_by_source = {}
                    chunks_by_query_type = {}
                    
                    # ä»å¡ç‰Œä¿¡æ¯ä¸­ç»Ÿè®¡
                    for card_id, card_data in card_info.items():
                        chunks = card_data.get('chunks', [])
                        for chunk in chunks:
                            source = chunk.get('source', 'unknown')
                            chunks_by_source[source] = chunks_by_source.get(source, 0) + 1
                    
                    # ä»å åœæ–¹æ³•ä¸­ç»Ÿè®¡
                    spread_chunks = spread_method.get('chunks', [])
                    for chunk in spread_chunks:
                        source = chunk.get('source', 'unknown')
                        chunks_by_source[source] = chunks_by_source.get(source, 0) + 1
                    
                    # ä»ç‰Œä¹‹é—´çš„å…³ç³»ä¸­ç»Ÿè®¡
                    relationship_chunks = card_relationships.get('chunks', [])
                    for chunk in relationship_chunks:
                        source = chunk.get('source', 'unknown')
                        chunks_by_source[source] = chunks_by_source.get(source, 0) + 1
                    
                    test_log['rag_analysis']['chunks_by_source'] = chunks_by_source
                    
                    # æŒ‰æŸ¥è¯¢ç±»å‹ç»Ÿè®¡
                    for query in rag_queries:
                        query_type = query.get('type', 'unknown')
                        chunks_by_query_type[query_type] = chunks_by_query_type.get(query_type, 0) + 1
                    
                    test_log['rag_analysis']['chunks_by_query_type'] = chunks_by_query_type
                    
                    print(f"\nğŸ“Š RAGæ£€ç´¢åˆ†æ:")
                    print(f"  - æ€»æŸ¥è¯¢æ•°: {len(rag_queries)}")
                    print(f"  - å»é‡å‰chunksæ•°: {total_before}")
                    print(f"  - å»é‡åchunksæ•°: {total_after}")
                    if total_before > 0:
                        print(f"  - å»é‡ç‡: {dedup_rate:.2f}%")
                    print(f"  - æŒ‰æ¥æºåˆ†å¸ƒ: {chunks_by_source}")
                
                # æ‰“å°æ­¥éª¤æ‘˜è¦
                print(f"\næ­¥éª¤ {step_data.get('step_order')}: {step_data.get('step_name')}")
                print(f"  - å¤„ç†æ—¶é—´: {step_data.get('processing_time_ms')}ms")
                if step_data.get('model_used'):
                    print(f"  - æ¨¡å‹: {step_data.get('model_used')}")
                if step_data.get('rag_queries'):
                    print(f"  - RAGæŸ¥è¯¢æ•°é‡: {len(step_data.get('rag_queries', []))}")
        
        # è®¡ç®—æ€»æ—¶é—´
        total_time_ms = int((time.time() - start_time) * 1000)
        test_log['total_time_ms'] = total_time_ms
        
        print(f"\nâœ… å®Œæ•´å åœæµç¨‹å®Œæˆ ({total_time_ms}ms)")
        print(f"âœ… å åœID: {reading_id}")
        
        # ä¿å­˜æµ‹è¯•æ—¥å¿—åˆ°æ–‡ä»¶
        log_filename = f"rag_no_intermediate_llm_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        result_dir = Path(__file__).parent / "result"
        result_dir.mkdir(exist_ok=True)
        log_path = result_dir / log_filename
        
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(test_log, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nâœ… æµ‹è¯•æ—¥å¿—å·²ä¿å­˜åˆ°: {log_path}")
        
        # åˆ†æç»“æœ
        print("\n" + "="*80)
        print("RAGæµç¨‹ä¼˜åŒ–åˆ†æ")
        print("="*80)
        
        rag_analysis = test_log['rag_analysis']
        print(f"\nğŸ“Š RAGæ£€ç´¢ç»Ÿè®¡:")
        print(f"  - æ€»æŸ¥è¯¢æ•°: {rag_analysis['total_queries']}")
        print(f"  - å»é‡å‰chunksæ•°: {rag_analysis['total_chunks_before_dedup']}")
        print(f"  - å»é‡åchunksæ•°: {rag_analysis['total_chunks_after_dedup']}")
        print(f"  - å»é‡ç‡: {rag_analysis['deduplication_rate']:.2f}%")
        print(f"  - æŒ‰æ¥æºåˆ†å¸ƒ: {rag_analysis['chunks_by_source']}")
        print(f"  - æŒ‰æŸ¥è¯¢ç±»å‹åˆ†å¸ƒ: {rag_analysis['chunks_by_query_type']}")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¸­é—´LLMè°ƒç”¨
        print(f"\nğŸ” æ£€æŸ¥ä¸­é—´LLMè°ƒç”¨:")
        rag_step = next((s for s in test_log['steps'] if s['step_name'] == 'rag_retrieval'), None)
        if rag_step:
            output_data = rag_step.get('output_data', {})
            card_info = output_data.get('card_information', {})
            
            has_rag_text = False
            has_chunks = False
            
            for card_id, card_data in card_info.items():
                if card_data.get('rag_text'):
                    has_rag_text = True
                if card_data.get('chunks'):
                    has_chunks = True
            
            if has_rag_text:
                print("  âš ï¸ å‘ç°rag_textå­—æ®µï¼ˆå¯èƒ½ä»åœ¨ä½¿ç”¨ä¸­é—´LLMè°ƒç”¨ï¼‰")
            else:
                print("  âœ… æœªå‘ç°rag_textå­—æ®µï¼ˆæœªä½¿ç”¨ä¸­é—´LLMè°ƒç”¨ï¼‰")
            
            if has_chunks:
                print("  âœ… å‘ç°chunkså­—æ®µï¼ˆä½¿ç”¨åŸå§‹chunksï¼‰")
            else:
                print("  âš ï¸ æœªå‘ç°chunkså­—æ®µ")
        
        # æ£€æŸ¥æœ€ç»ˆè§£è¯»prompt
        print(f"\nğŸ” æ£€æŸ¥æœ€ç»ˆè§£è¯»prompt:")
        interpretation_step = next((s for s in test_log['steps'] if s['step_name'] == 'final_interpretation'), None)
        if interpretation_step:
            prompt_content = interpretation_step.get('prompt_content', '')
            if 'RAGæ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼ˆåŸå§‹æ–‡æ¡£ç‰‡æ®µï¼‰' in prompt_content:
                print("  âœ… PromptåŒ…å«åŸå§‹æ–‡æ¡£ç‰‡æ®µ")
            else:
                print("  âš ï¸ Promptå¯èƒ½ä¸åŒ…å«åŸå§‹æ–‡æ¡£ç‰‡æ®µ")
            
            # ç»Ÿè®¡promptä¸­çš„chunksæ•°é‡
            chunk_count = prompt_content.count('[1]') + prompt_content.count('[2]') + prompt_content.count('[3]')
            print(f"  - Promptä¸­chunksæ•°é‡ï¼ˆä¼°ç®—ï¼‰: {chunk_count}")
        
        return test_log
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        error_traceback = traceback.format_exc()
        test_log['errors'].append({
            'error': str(e),
            'traceback': error_traceback
        })
        
        # ä¿å­˜é”™è¯¯æ—¥å¿—
        log_filename = f"rag_no_intermediate_llm_error_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        result_dir = Path(__file__).parent / "result"
        result_dir.mkdir(exist_ok=True)
        log_path = result_dir / log_filename
        
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(test_log, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nâŒ é”™è¯¯æ—¥å¿—å·²ä¿å­˜åˆ°: {log_path}")
        traceback.print_exc()
        return test_log


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "="*80)
    print("RAGæµç¨‹ä¼˜åŒ–æµ‹è¯•ï¼ˆä¸ä½¿ç”¨ä¸­é—´LLMè°ƒç”¨ï¼‰")
    print("="*80)
    print("\næ­¤æµ‹è¯•å°†éªŒè¯ï¼š")
    print("  1. RAGæ£€ç´¢ä¸å†è°ƒç”¨ä¸­é—´LLMï¼ˆåªè¿”å›åŸå§‹chunksï¼‰")
    print("  2. æ‰€æœ‰chunksåœ¨æœ€åç»Ÿä¸€å»é‡")
    print("  3. æœ€ç»ˆè§£è¯»promptä½¿ç”¨åŸå§‹chunksè€Œä¸æ˜¯LLMç”Ÿæˆçš„ç­”æ¡ˆ")
    print("  4. è®°å½•chunksæ”¶é›†å’Œå»é‡ç»Ÿè®¡")
    print("\nè¯·ç¡®ä¿å·²é…ç½®ç¯å¢ƒå˜é‡ï¼ˆOPENROUTER_API_KEYæˆ–OPENAI_API_KEYï¼‰")
    print("è¯·ç¡®ä¿å·²é…ç½®Supabaseè¿æ¥ï¼ˆSUPABASE_URLå’ŒSUPABASE_SERVICE_ROLE_KEYï¼‰")
    print("="*80)
    
    try:
        # è¿è¡Œæµ‹è¯•
        test_log = await test_rag_no_intermediate_llm()
        
        print("\n" + "="*80)
        print("âœ… æµ‹è¯•å®Œæˆ")
        print("="*80)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())




