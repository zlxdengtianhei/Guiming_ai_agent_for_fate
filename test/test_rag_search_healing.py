#!/usr/bin/env python3
"""
RAGæœç´¢æµ‹è¯•è„šæœ¬ - æœç´¢å¡”ç½—ç‰Œå¿ƒç†ç–—æ„ˆä¸å†¥æƒ³ç›¸å…³å†…å®¹
è¿è¡Œ: python3 test/test_rag_search_healing.py
"""

import asyncio
import sys
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ backendç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
backend_dir = project_root / "backend"
sys.path.insert(0, str(backend_dir))

from app.services.rag import rag_service
from app.services.rag_database import rag_db
from app.core.config import settings


async def search_healing_meditation():
    """æœç´¢å¡”ç½—ç‰Œå¿ƒç†ç–—æ„ˆä¸å†¥æƒ³ç›¸å…³å†…å®¹"""
    print("\n" + "="*80)
    print("RAGæœç´¢: ä½¿ç”¨å¡”ç½—ç‰Œè¿›è¡Œå¿ƒç†ç–—æ„ˆä¸å†¥æƒ³çš„æ­¥éª¤")
    print("="*80)
    
    # 1. æµ‹è¯•æ•°æ®åº“è¿æ¥
    print("\n1. æ£€æŸ¥æ•°æ®åº“è¿æ¥...")
    try:
        health = await rag_db.health_check()
        if not health:
            print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
            return
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
        return
    
    # 2. æ£€æŸ¥æ•°æ®åº“ç»Ÿè®¡
    print("\n2. æ£€æŸ¥æ•°æ®åº“å†…å®¹...")
    try:
        stats = await rag_service.get_stats()
        if stats:
            total_chunks = stats.get('total_chunks', 0)
            print(f"ğŸ“Š æ•°æ®åº“ä¸­æœ‰ {total_chunks} ä¸ªchunks")
            if total_chunks == 0:
                print("âš ï¸  è­¦å‘Š: æ•°æ®åº“ä¸ºç©ºï¼Œéœ€è¦å…ˆä¸Šä¼ æ–‡æ¡£")
                return
        else:
            print("âš ï¸  æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯")
    except Exception as e:
        print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return
    
    # 3. æ‰§è¡Œæœç´¢
    print("\n3. æ‰§è¡ŒRAGæœç´¢...")
    query = "steps for using tarot cards for psychological healing and meditation"
    print(f"æŸ¥è¯¢: {query}")
    print("-" * 80)
    
    try:
        # ä½¿ç”¨ search_only æ–¹æ³•ï¼Œåªè¿”å›ç›¸å…³æ–‡æ¡£ï¼Œä¸ç”Ÿæˆç­”æ¡ˆ
        result = await rag_service.search_only(
            query=query,
            top_k=10,  # è·å–æ›´å¤šç»“æœ
            balance_sources=True,
            min_similarity=0.25  # é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ä»¥è·å–æ›´å¤šç›¸å…³ç»“æœ
        )
        
        if not result:
            print("âŒ æœç´¢è¿”å›ç©ºç»“æœ")
            return
        
        chunks = result.get('chunks', [])
        citations = result.get('citations', [])
        debug = result.get('debug', {})
        
        print(f"\nâœ… æœç´¢æˆåŠŸï¼")
        print(f"ğŸ“Š æ‰¾åˆ° {len(chunks)} ä¸ªç›¸å…³æ–‡æ¡£å—")
        print(f"â±ï¸  æœç´¢å»¶è¿Ÿ: {debug.get('latency_ms', 0)}ms")
        
        if not chunks:
            print("\nâš ï¸  æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œå¯èƒ½çš„åŸå› ï¼š")
            print("   - æ•°æ®åº“ä¸­ä¸åŒ…å«å¿ƒç†ç–—æ„ˆæˆ–å†¥æƒ³ç›¸å…³çš„å†…å®¹")
            print("   - å°è¯•é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼æˆ–ä½¿ç”¨ä¸åŒçš„å…³é”®è¯")
            return
        
        # 4. æ˜¾ç¤ºæœç´¢ç»“æœ
        print("\n" + "="*80)
        print("æœç´¢ç»“æœè¯¦æƒ…:")
        print("="*80)
        
        for i, chunk in enumerate(chunks, 1):
            print(f"\nã€ç»“æœ {i}ã€‘")
            print(f"æ¥æº: {chunk.get('source', 'unknown')}")
            print(f"ç›¸ä¼¼åº¦: {chunk.get('similarity', 0):.4f}")
            print(f"Chunk ID: {chunk.get('chunk_id', 'N/A')}")
            print(f"\nå†…å®¹:")
            print("-" * 80)
            text = chunk.get('text', '')
            # æ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦ï¼Œå¦‚æœå†…å®¹æ›´é•¿åˆ™æˆªæ–­
            if len(text) > 500:
                print(text[:500] + "...")
                print(f"\n[å†…å®¹å·²æˆªæ–­ï¼Œå®Œæ•´é•¿åº¦: {len(text)} å­—ç¬¦]")
            else:
                print(text)
            print("-" * 80)
        
        # 5. æŒ‰æ¥æºåˆ†ç»„ç»Ÿè®¡
        print("\n" + "="*80)
        print("æŒ‰æ¥æºç»Ÿè®¡:")
        print("="*80)
        sources = {}
        for chunk in chunks:
            source = chunk.get('source', 'unknown')
            if source not in sources:
                sources[source] = []
            sources[source].append(chunk)
        
        for source, source_chunks in sources.items():
            avg_similarity = sum(c.get('similarity', 0) for c in source_chunks) / len(source_chunks)
            print(f"\n{source}:")
            print(f"  - ç»“æœæ•°: {len(source_chunks)}")
            print(f"  - å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.4f}")
        
        # 6. ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        result_dir = project_root / "test" / "result"
        result_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = int(datetime.now().timestamp())
        output_file = result_dir / f"rag_search_healing_{timestamp}.json"
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            "query": query,
            "timestamp": datetime.now().isoformat(),
            "search_stats": {
                "total_chunks": len(chunks),
                "latency_ms": debug.get('latency_ms', 0),
                "sources": {
                    source: {
                        "count": len(source_chunks),
                        "avg_similarity": sum(c.get('similarity', 0) for c in source_chunks) / len(source_chunks)
                    }
                    for source, source_chunks in sources.items()
                }
            },
            "chunks": [
                {
                    "index": i + 1,
                    "source": chunk.get('source', 'unknown'),
                    "chunk_id": chunk.get('chunk_id', 'N/A'),
                    "similarity": chunk.get('similarity', 0),
                    "text": chunk.get('text', ''),
                    "metadata": chunk.get('metadata', {})
                }
                for i, chunk in enumerate(chunks)
            ],
            "citations": citations,
            "debug": debug
        }
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        print("\n" + "="*80)
        print("âœ… æœç´¢å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        print("="*80)
        
    except Exception as e:
        print(f"\nâŒ æœç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("\né…ç½®ä¿¡æ¯:")
    print(f"  - Supabase URL: {settings.supabase_url[:50] if settings.supabase_url else 'Not set'}...")
    print(f"  - ä½¿ç”¨ OpenRouter: {settings.use_openrouter}")
    print(f"  - RAG Top K: {settings.rag_top_k}")
    
    asyncio.run(search_healing_meditation())

