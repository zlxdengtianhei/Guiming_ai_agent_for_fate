#!/usr/bin/env python3
"""
å›¾åƒç”Ÿæˆæ¨¡å‹å¯¹æ¯”è„šæœ¬
ä½¿ç”¨ç›¸åŒçš„ prompt æµ‹è¯•ä¸åŒçš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¹¶ä¿å­˜ç»“æœåˆ°å¯¹æ¯”æ–‡ä»¶å¤¹
"""

import os
import sys
import json
import time
import base64
from pathlib import Path
from typing import Optional, Dict, Any, List

try:
    import requests
except ImportError:
    print("âŒ éœ€è¦å®‰è£… requests åº“")
    print("   è¿è¡Œ: pip install requests")
    sys.exit(1)

try:
    import openai
except ImportError:
    print("âš ï¸  è­¦å‘Š: æœªå®‰è£… openai åº“ï¼Œæ— æ³•ä½¿ç”¨ DALL-E 3")
    print("   å¦‚éœ€ä½¿ç”¨ DALL-E 3ï¼Œè¯·è¿è¡Œ: pip install openai")

# æ·»åŠ backendç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
backend_dir = project_root / "backend"
sys.path.insert(0, str(backend_dir))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
env_path = backend_dir / ".env"
if env_path.exists():
    load_dotenv(env_path)
else:
    print("âš ï¸  è­¦å‘Š: .env æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡")


def get_openai_org_id() -> Optional[str]:
    """ä»ç¯å¢ƒå˜é‡æˆ– .env æ–‡ä»¶è¯»å– OpenAI Organization ID"""
    org_id = os.getenv("OPENAI_ORG_ID", "").strip()
    
    if not org_id and env_path.exists():
        import re
        with open(env_path, 'r', encoding='utf-8') as f:
            content = f.read()
        match = re.search(r'^OPENAI_ORG_ID=(.+)$', content, re.MULTILINE)
        if match:
            org_id = match.group(1).strip().strip('"').strip("'")
    
    return org_id if org_id else None


class ImageGenerator:
    """å›¾åƒç”Ÿæˆå™¨åŸºç±»"""
    
    def generate_image(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾ç‰‡ï¼Œè¿”å›åŒ…å«å›¾ç‰‡æ•°æ®çš„å­—å…¸"""
        raise NotImplementedError
    
    def download_image(self, image_data: Any, save_path: Path) -> bool:
        """ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°"""
        raise NotImplementedError


class AliyunGenerator(ImageGenerator):
    """é˜¿é‡Œäº‘é€šä¹‰ä¸‡ç›¸æ–‡ç”Ÿå›¾"""
    
    def __init__(self, model: str = "wan2.5-t2i-preview"):
        """
        åˆå§‹åŒ–é˜¿é‡Œäº‘ç”Ÿæˆå™¨
        
        Args:
            model: æ¨¡å‹åç§°ï¼Œå¯é€‰å€¼ï¼š
                - wan2.5-t2i-preview: é€šä¹‰ä¸‡ç›¸ 2.5 é¢„è§ˆç‰ˆï¼ˆé»˜è®¤ï¼‰
                - wan2.1-t2i-turbo: é€šä¹‰ä¸‡ç›¸ 2.1 æé€Ÿç‰ˆ
                - wan2.1-t2i-plus: é€šä¹‰ä¸‡ç›¸ 2.1 ä¸“ä¸šç‰ˆ
        """
        api_key = os.getenv("ALIYUN_DASHSCOPE_API_KEY", "").strip()
        if not api_key:
            raise ValueError("éœ€è¦è®¾ç½® ALIYUN_DASHSCOPE_API_KEY")
        
        region = os.getenv("ALIYUN_DASHSCOPE_REGION", "singapore")
        if region == "beijing":
            self.base_url = "https://dashscope.aliyuncs.com/api/v1"
        else:
            self.base_url = "https://dashscope-intl.aliyuncs.com/api/v1"
        
        self.api_key = api_key
        self.model = model
        self.create_task_url = f"{self.base_url}/services/aigc/text2image/image-synthesis"
        self.query_task_url = f"{self.base_url}/tasks"
    
    def create_task(self, prompt: str, size: str = "768*1152") -> str:
        """åˆ›å»ºä»»åŠ¡å¹¶è¿”å› task_id"""
        headers = {
            "X-DashScope-Async": "enable",
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "input": {"prompt": prompt},
            "parameters": {"size": size, "n": 1}
        }
        
        response = requests.post(self.create_task_url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        return result.get("output", {}).get("task_id")
    
    def wait_for_result(self, task_id: str, max_wait_time: int = 300) -> Dict[str, Any]:
        """ç­‰å¾…ä»»åŠ¡å®Œæˆ"""
        start_time = time.time()
        while True:
            if time.time() - start_time > max_wait_time:
                return {"error": "timeout"}
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            response = requests.get(f"{self.query_task_url}/{task_id}", headers=headers, timeout=30)
            response.raise_for_status()
            result = response.json()
            
            task_status = result.get("output", {}).get("task_status")
            if task_status == "SUCCEEDED":
                return result
            elif task_status == "FAILED":
                return {"error": "failed", "result": result}
            
            time.sleep(5)
    
    def generate_image(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾ç‰‡"""
        size = kwargs.get("size", "768*1152")
        task_id = self.create_task(prompt, size)
        result = self.wait_for_result(task_id)
        
        if "error" in result:
            raise Exception(f"ä»»åŠ¡å¤±è´¥: {result.get('error')}")
        
        results = result.get("output", {}).get("results", [])
        if not results:
            raise Exception("æœªè¿”å›ç»“æœ")
        
        image_url = results[0].get("url", "")
        if not image_url:
            raise Exception("æœªæ‰¾åˆ°å›¾ç‰‡URL")
        
        return {"url": image_url, "type": "url"}
    
    def download_image(self, image_data: Any, save_path: Path) -> bool:
        """ä¸‹è½½å›¾ç‰‡"""
        image_url = image_data.get("url")
        if not image_url:
            return False
        
        response = requests.get(image_url, timeout=60, stream=True)
        response.raise_for_status()
        
        save_path.parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        return True


class Dalle3Generator(ImageGenerator):
    """OpenAI DALL-E 3"""
    
    def __init__(self):
        if not openai:
            raise ValueError("éœ€è¦å®‰è£… openai åº“")
        
        # å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å– OPENAI_API_KEY
        api_key = os.getenv("OPENAI_API_KEY", "").strip()
        
        # å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ï¼Œå°è¯•ç›´æ¥ä» .env æ–‡ä»¶è¯»å–
        if not api_key:
            import re
            env_file = backend_dir / ".env"
            if env_file.exists():
                with open(env_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                match = re.search(r'^OPENAI_API_KEY=(.+)$', content, re.MULTILINE)
                if match:
                    api_key = match.group(1).strip().strip('"').strip("'")
        
        if not api_key:
            raise ValueError("éœ€è¦è®¾ç½® OPENAI_API_KEY")
        
        # è¯»å– organization ID
        org_id = get_openai_org_id()
        client_kwargs = {"api_key": api_key}
        if org_id:
            client_kwargs["organization"] = org_id
        
        self.client = openai.OpenAI(**client_kwargs)
        self.model = "dall-e-3"
    
    def generate_image(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾ç‰‡"""
        size = kwargs.get("size", "1024x1792")
        quality = kwargs.get("quality", "hd")
        style = kwargs.get("style", "vivid")
        n = kwargs.get("n", 1)
        
        # DALL-E 3 åªæ”¯æŒ n=1ï¼Œå¼ºåˆ¶è®¾ç½®ä¸º 1
        if n > 1:
            print(f"   âš ï¸  æ³¨æ„ï¼šDALL-E 3 åªæ”¯æŒç”Ÿæˆ 1 å¼ å›¾ç‰‡ï¼Œå°†å¿½ç•¥ n={n} å‚æ•°")
            n = 1
        
        # DALL-E 3 API è°ƒç”¨ï¼ˆåªç”Ÿæˆ 1 å¼ ï¼‰
        response = self.client.images.generate(
            model=self.model,
            prompt=prompt,
            size=size,
            quality=quality,
            style=style,
            n=1  # DALL-E 3 åªæ”¯æŒ n=1
        )
        
        image_url = response.data[0].url
        revised_prompt = getattr(response.data[0], 'revised_prompt', None)
        
        return {
            "url": image_url,
            "revised_prompt": revised_prompt,
            "type": "url"
        }
    
    def download_image(self, image_data: Any, save_path: Path) -> bool:
        """ä¸‹è½½å›¾ç‰‡ï¼ˆæ”¯æŒå•å¼ æˆ–å¤šå¼ ï¼‰"""
        # å¤„ç†å¤šå¼ å›¾ç‰‡çš„æƒ…å†µ
        if image_data.get("type") == "url_multiple":
            image_urls = image_data.get("url_list", [])
            if not image_urls:
                return False
            
            save_path.parent.mkdir(parents=True, exist_ok=True)
            base_name = save_path.stem
            extension = save_path.suffix
            parent_dir = save_path.parent
            
            for idx, image_url in enumerate(image_urls):
                response = requests.get(image_url, timeout=60, stream=True)
                response.raise_for_status()
                
                if len(image_urls) > 1:
                    # å¤šå¼ å›¾ç‰‡ï¼šæ·»åŠ åºå·
                    multi_path = parent_dir / f"{base_name}_{idx+1}{extension}"
                else:
                    multi_path = save_path
                
                with open(multi_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
            return True
        
        # å¤„ç†å•å¼ å›¾ç‰‡çš„æƒ…å†µ
        image_url = image_data.get("url")
        if not image_url:
            return False
        
        response = requests.get(image_url, timeout=60, stream=True)
        response.raise_for_status()
        
        save_path.parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        return True


class GPT5ImageGenerator(ImageGenerator):
    """OpenAI GPT-5 Image ç³»åˆ—ï¼ˆä½¿ç”¨ Responses APIï¼‰"""
    
    def __init__(self, model: str = "gpt-5"):
        """
        åˆå§‹åŒ– GPT-5 Image ç”Ÿæˆå™¨
        
        Args:
            model: æ¨¡å‹åç§°ï¼Œå¯é€‰å€¼ï¼š
                - "gpt-5" - GPT-5 Imageï¼ˆæ ‡å‡†ç‰ˆï¼‰
                - "gpt-5-mini" - GPT-5 Image Miniï¼ˆMini ç‰ˆï¼‰
        """
        if not openai:
            raise ValueError("éœ€è¦å®‰è£… openai åº“")
        
        # å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å– OPENAI_API_KEY
        api_key = os.getenv("OPENAI_API_KEY", "").strip()
        
        # å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ï¼Œå°è¯•ç›´æ¥ä» .env æ–‡ä»¶è¯»å–
        if not api_key:
            import re
            env_file = backend_dir / ".env"
            if env_file.exists():
                with open(env_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                match = re.search(r'^OPENAI_API_KEY=(.+)$', content, re.MULTILINE)
                if match:
                    api_key = match.group(1).strip().strip('"').strip("'")
        
        if not api_key:
            raise ValueError(
                "éœ€è¦è®¾ç½® OPENAI_API_KEY\n"
                "è¯·åœ¨ backend/.env æ–‡ä»¶ä¸­æ·»åŠ ï¼šOPENAI_API_KEY=your_key_here\n"
                "æˆ–è€…è®¾ç½®ä¸ºç³»ç»Ÿç¯å¢ƒå˜é‡ï¼šexport OPENAI_API_KEY=your_key_here"
            )
        
        # è¯»å– organization ID
        org_id = get_openai_org_id()
        client_kwargs = {"api_key": api_key}
        if org_id:
            client_kwargs["organization"] = org_id
        
        self.client = openai.OpenAI(**client_kwargs)
        self.model = model
    
    def generate_image(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """
        ç”Ÿæˆå›¾ç‰‡ï¼ˆä½¿ç”¨ Responses APIï¼‰
        
        Args:
            prompt: æ–‡æœ¬æç¤ºè¯
            **kwargs: é¢å¤–å‚æ•°
                - size: å›¾ç‰‡å°ºå¯¸ï¼Œæ”¯æŒ "1024x1024", "1024x1536", "1536x1024"ï¼ˆé»˜è®¤: "1024x1536"ï¼‰
                - quality: å›¾ç‰‡è´¨é‡ï¼Œ"low", "medium", "high"ï¼ˆé»˜è®¤: "high"ï¼‰
                - n: ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆé»˜è®¤: 1ï¼‰
                æ³¨æ„ï¼šGPT-5 Image ç³»åˆ—ä½¿ç”¨ Responses APIï¼Œä¸€æ¬¡è¯·æ±‚åªèƒ½ç”Ÿæˆä¸€å¼ å›¾ç‰‡
                å¦‚éœ€ç”Ÿæˆå¤šå¼ ï¼Œéœ€è¦å¤šæ¬¡è°ƒç”¨æˆ–ä½¿ç”¨ batch API
        """
        size = kwargs.get("size", "1024x1536")  # é»˜è®¤ä½¿ç”¨ç«–å± 2:3 æ¯”ä¾‹
        quality = kwargs.get("quality", "high")
        n = kwargs.get("n", 1)
        
        if n > 1:
            print(f"   âš ï¸  æ³¨æ„ï¼šGPT-5 Image ç³»åˆ—ä¸€æ¬¡è¯·æ±‚åªèƒ½ç”Ÿæˆ 1 å¼ å›¾ç‰‡")
            print(f"   å¦‚éœ€ç”Ÿæˆ {n} å¼ ï¼Œéœ€è¦è°ƒç”¨ {n} æ¬¡ API æˆ–ä½¿ç”¨ batch API")
        
        print(f"   ä½¿ç”¨ OpenAI Responses API ç”Ÿæˆå›¾ç‰‡")
        print(f"   æ¨¡å‹: {self.model}")
        print(f"   å°ºå¯¸: {size} ({'2:3 ç«–å±' if size == '1024x1536' else '3:2 æ¨ªå±' if size == '1536x1024' else '1:1 æ­£æ–¹å½¢'})")
        print(f"   è´¨é‡: {quality}")
        
        # ä½¿ç”¨ Responses API
        # æ³¨æ„ï¼šGPT-5 Image ç³»åˆ—ä¸€æ¬¡è¯·æ±‚åªèƒ½ç”Ÿæˆ 1 å¼ å›¾ç‰‡
        # å¦‚æœéœ€è¦å¤šå¼ ï¼Œéœ€è¦å¤šæ¬¡è°ƒç”¨
        images_base64 = []
        for i in range(n):
            if n > 1:
                print(f"   ç”Ÿæˆç¬¬ {i+1}/{n} å¼ å›¾ç‰‡...")
            
            response = self.client.responses.create(
                model=self.model,
                input=prompt,
                tools=[{
                    "type": "image_generation",
                    "size": size,
                    "quality": quality
                }]
            )
            
            # ä»å“åº”ä¸­æå–å›¾ç‰‡æ•°æ®
            image_data = [
                output.result
                for output in response.output
                if output.type == "image_generation_call"
            ]
            
            if not image_data:
                raise Exception(f"ç¬¬ {i+1} å¼ å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼šæœªæ‰¾åˆ°ç”Ÿæˆçš„å›¾ç‰‡æ•°æ®")
            
            images_base64.append(image_data[0])
        
        # å¦‚æœåªç”Ÿæˆä¸€å¼ ï¼Œè¿”å›å•å¼ æ ¼å¼ï¼›å¦åˆ™è¿”å›å¤šå¼ æ ¼å¼
        if n == 1:
            return {
                "b64_json": images_base64[0],
                "type": "base64"
            }
        else:
            return {
                "b64_json_list": images_base64,
                "type": "base64_multiple",
                "count": len(images_base64)
            }
    
    def download_image(self, image_data: Any, save_path: Path) -> bool:
        """ä¿å­˜ base64 å›¾ç‰‡ï¼ˆæ”¯æŒå•å¼ æˆ–å¤šå¼ ï¼‰"""
        # å¤„ç†å¤šå¼ å›¾ç‰‡çš„æƒ…å†µ
        if image_data.get("type") == "base64_multiple":
            images_base64 = image_data.get("b64_json_list", [])
            if not images_base64:
                return False
            
            save_path.parent.mkdir(parents=True, exist_ok=True)
            # ä¿å­˜å¤šå¼ å›¾ç‰‡ï¼Œæ–‡ä»¶åæ·»åŠ åºå·
            base_name = save_path.stem
            extension = save_path.suffix
            parent_dir = save_path.parent
            
            for idx, image_base64 in enumerate(images_base64):
                image_bytes = base64.b64decode(image_base64)
                if len(images_base64) > 1:
                    # å¤šå¼ å›¾ç‰‡ï¼šæ·»åŠ åºå·
                    multi_path = parent_dir / f"{base_name}_{idx+1}{extension}"
                else:
                    multi_path = save_path
                with open(multi_path, 'wb') as f:
                    f.write(image_bytes)
            return True
        
        # å¤„ç†å•å¼ å›¾ç‰‡çš„æƒ…å†µ
        image_base64 = image_data.get("b64_json")
        if not image_base64:
            return False
        
        image_bytes = base64.b64decode(image_base64)
        
        save_path.parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, 'wb') as f:
            f.write(image_bytes)
        return True


class GPTImageGenerator(ImageGenerator):
    """OpenAI GPT-Image-1 ç³»åˆ—ï¼ˆç›´æ¥ä½¿ç”¨ OpenAI APIï¼‰"""
    
    def __init__(self, model: str = "gpt-image-1"):
        """
        åˆå§‹åŒ– GPT-Image ç”Ÿæˆå™¨
        
        Args:
            model: æ¨¡å‹åç§°ï¼Œå¯é€‰å€¼ï¼š
                - "gpt-image-1" - GPT-Image-1ï¼ˆæ ‡å‡†ç‰ˆï¼‰
                - "gpt-image-1-mini" - GPT-Image-1 Miniï¼ˆMini ç‰ˆï¼‰
        """
        if not openai:
            raise ValueError("éœ€è¦å®‰è£… openai åº“")
        
        # å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å– OPENAI_API_KEY
        api_key = os.getenv("OPENAI_API_KEY", "").strip()
        
        # å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ï¼Œå°è¯•ç›´æ¥ä» .env æ–‡ä»¶è¯»å–
        if not api_key:
            import re
            env_file = backend_dir / ".env"
            if env_file.exists():
                with open(env_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                match = re.search(r'^OPENAI_API_KEY=(.+)$', content, re.MULTILINE)
                if match:
                    api_key = match.group(1).strip().strip('"').strip("'")
        
        if not api_key:
            raise ValueError(
                "éœ€è¦è®¾ç½® OPENAI_API_KEY\n"
                "è¯·åœ¨ backend/.env æ–‡ä»¶ä¸­æ·»åŠ ï¼šOPENAI_API_KEY=your_key_here\n"
                "æˆ–è€…è®¾ç½®ä¸ºç³»ç»Ÿç¯å¢ƒå˜é‡ï¼šexport OPENAI_API_KEY=your_key_here"
            )
        
        # è¯»å– organization ID
        org_id = get_openai_org_id()
        client_kwargs = {"api_key": api_key}
        if org_id:
            client_kwargs["organization"] = org_id
        
        self.client = openai.OpenAI(**client_kwargs)
        self.model = model
    
    def generate_image(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """
        ç”Ÿæˆå›¾ç‰‡
        
        Args:
            prompt: æ–‡æœ¬æç¤ºè¯
            **kwargs: é¢å¤–å‚æ•°
                - size: å›¾ç‰‡å°ºå¯¸ï¼Œæ”¯æŒ "1024x1024", "1024x1536", "1536x1024"ï¼ˆé»˜è®¤: "1024x1536"ï¼‰
                  æ³¨æ„ï¼š1024x1536 æ˜¯ 2:3 ç«–å±ï¼Œ1536x1024 æ˜¯ 3:2 æ¨ªå±
                - quality: å›¾ç‰‡è´¨é‡ï¼Œ"low", "medium", "high"ï¼ˆé»˜è®¤: "high"ï¼‰
                - n: ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼Œ1-10ï¼ˆé»˜è®¤: 1ï¼‰
        """
        # æ ¹æ®æ¨¡å‹è®¾ç½®é»˜è®¤è´¨é‡
        if "mini" in self.model.lower():
            default_quality = "medium"  # GPT-Image-1-Mini é»˜è®¤è´¨é‡æ˜¯ medium
        else:
            default_quality = "high"  # GPT-Image-1 é»˜è®¤è´¨é‡æ˜¯ high
        
        size = kwargs.get("size", "1024x1536")  # é»˜è®¤ä½¿ç”¨ç«–å± 2:3 æ¯”ä¾‹ (1024Ã—1536)
        quality = kwargs.get("quality", default_quality)
        n = kwargs.get("n", 1)
        
        print(f"   ä½¿ç”¨ OpenAI API ç”Ÿæˆå›¾ç‰‡")
        print(f"   æ¨¡å‹: {self.model}")
        print(f"   å°ºå¯¸: {size} ({'2:3 ç«–å±' if size == '1024x1536' else '3:2 æ¨ªå±' if size == '1536x1024' else '1:1 æ­£æ–¹å½¢'})")
        print(f"   è´¨é‡: {quality}")
        
        response = self.client.images.generate(
            model=self.model,
            prompt=prompt,
            size=size,
            quality=quality,
            n=n
        )
        
        # GPT-Image-1 è¿”å› base64 ç¼–ç çš„å›¾ç‰‡
        # å¦‚æœ n > 1ï¼Œè¿”å›å¤šå¼ å›¾ç‰‡
        if n > 1:
            images_base64 = [item.b64_json for item in response.data]
            return {
                "b64_json_list": images_base64,
                "type": "base64_multiple",
                "count": len(images_base64)
            }
        else:
            image_base64 = response.data[0].b64_json
            return {
                "b64_json": image_base64,
                "type": "base64"
            }
    
    def download_image(self, image_data: Any, save_path: Path) -> bool:
        """ä¿å­˜ base64 å›¾ç‰‡ï¼ˆæ”¯æŒå•å¼ æˆ–å¤šå¼ ï¼‰"""
        # å¤„ç†å¤šå¼ å›¾ç‰‡çš„æƒ…å†µ
        if image_data.get("type") == "base64_multiple":
            images_base64 = image_data.get("b64_json_list", [])
            if not images_base64:
                return False
            
            save_path.parent.mkdir(parents=True, exist_ok=True)
            # ä¿å­˜å¤šå¼ å›¾ç‰‡ï¼Œæ–‡ä»¶åæ·»åŠ åºå·
            base_name = save_path.stem
            extension = save_path.suffix
            parent_dir = save_path.parent
            
            for idx, image_base64 in enumerate(images_base64):
                image_bytes = base64.b64decode(image_base64)
                if len(images_base64) > 1:
                    # å¤šå¼ å›¾ç‰‡ï¼šæ·»åŠ åºå·
                    multi_path = parent_dir / f"{base_name}_{idx+1}{extension}"
                else:
                    multi_path = save_path
                with open(multi_path, 'wb') as f:
                    f.write(image_bytes)
            return True
        
        # å¤„ç†å•å¼ å›¾ç‰‡çš„æƒ…å†µ
        image_base64 = image_data.get("b64_json")
        if not image_base64:
            return False
        
        image_bytes = base64.b64decode(image_base64)
        
        save_path.parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, 'wb') as f:
            f.write(image_bytes)
        return True


class OpenRouterImageGenerator(ImageGenerator):
    """OpenRouter å›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆä½¿ç”¨ chat/completions APIï¼‰"""
    
    def __init__(self, model_id: str):
        api_key = os.getenv("OPENROUTER_API_KEY", "").strip()
        if not api_key:
            raise ValueError("éœ€è¦è®¾ç½® OPENROUTER_API_KEY")
        
        if not openai:
            raise ValueError("éœ€è¦å®‰è£… openai åº“")
        
        self.model_id = model_id
        self.client = openai.OpenAI(
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            default_headers={
                "HTTP-Referer": "https://github.com/yourusername/tarot_agent",
                "X-Title": "Tarot Agent"
            }
        )
    
    def generate_image(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """
        ç”Ÿæˆå›¾ç‰‡
        
        Args:
            prompt: æ–‡æœ¬æç¤ºè¯
            **kwargs: é¢å¤–å‚æ•°
                - aspect_ratio: å›¾ç‰‡æ¯”ä¾‹ï¼Œä¾‹å¦‚ "3:2", "16:9", "1:1", "2:3" ç­‰
                  æ”¯æŒçš„ Gemini æ¨¡å‹æ¯”ä¾‹ï¼š
                  - 1:1 (1024Ã—1024, é»˜è®¤)
                  - 2:3 (832Ã—1248ï¼Œæˆ– GPT-5 Image Mini çš„ 1024Ã—1536)
                  - 3:2 (1248Ã—832)
                  - 3:4 (864Ã—1184)
                  - 4:3 (1184Ã—864)
                  - 4:5 (896Ã—1152)
                  - 5:4 (1152Ã—896)
                  - 9:16 (768Ã—1344)
                  - 16:9 (1344Ã—768)
                  - 21:9 (1536Ã—672)
        """
        try:
            aspect_ratio = kwargs.get("aspect_ratio")
            
            # æ£€æµ‹æ˜¯å¦æ˜¯ GPT-5 Image ç³»åˆ—æ¨¡å‹
            is_gpt5_image = "gpt-5-image" in self.model_id.lower()
            
            # å¯¹äº GPT-5 Image ç³»åˆ—ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®š aspect_ratioï¼Œé»˜è®¤ä½¿ç”¨ 2:3ï¼ˆç«–å± 1024Ã—1536ï¼‰
            if is_gpt5_image and not aspect_ratio:
                aspect_ratio = "2:3"
                print(f"   æ£€æµ‹åˆ° GPT-5 Image æ¨¡å‹ï¼Œè‡ªåŠ¨ä½¿ç”¨ç«–å±æ¯”ä¾‹ 2:3 (1024Ã—1536)")
            
            # å¯¹äº GPT-5 Image ç³»åˆ—ï¼Œåœ¨ prompt ä¸­æ·»åŠ å°ºå¯¸è¦æ±‚
            # æ³¨æ„ï¼šOpenRouter çš„ GPT-5 Image ç³»åˆ—å¯èƒ½ä¸æ”¯æŒé€šè¿‡ image_config è®¾ç½®å°ºå¯¸
            # å› æ­¤éœ€è¦åœ¨ prompt ä¸­éå¸¸æ˜ç¡®åœ°æŒ‡å®šå°ºå¯¸è¦æ±‚
            final_prompt = prompt
            if is_gpt5_image and aspect_ratio == "2:3":
                # åœ¨ prompt å¼€å¤´å’Œæœ«å°¾éƒ½æ·»åŠ æ˜ç¡®çš„å°ºå¯¸è¦æ±‚
                # ä½¿ç”¨å¤šç§è¡¨è¾¾æ–¹å¼ç¡®ä¿æ¨¡å‹ç†è§£
                size_note_start = "CRITICAL: You MUST generate this image with EXACT dimensions: width 1024 pixels, height 1536 pixels (portrait orientation, 2:3 aspect ratio). "
                size_note_end = " REMINDER: The final image MUST be exactly 1024 pixels wide and 1536 pixels tall (portrait, 2:3 ratio). Do NOT generate a square image."
                if not prompt.startswith(size_note_start):
                    final_prompt = size_note_start + prompt + size_note_end
                    print(f"   å·²åœ¨ prompt ä¸­æ·»åŠ å°ºå¯¸è¦æ±‚: 1024Ã—1536 (portrait)")
                elif not prompt.endswith(size_note_end):
                    final_prompt = prompt + size_note_end
                    print(f"   å·²åœ¨ prompt æœ«å°¾æ·»åŠ å°ºå¯¸è¦æ±‚: 1024Ã—1536 (portrait)")
            
            # å¯¹äº GPT-5 Image ç³»åˆ—ï¼Œå°è¯•ä½¿ç”¨å·¥å…·è°ƒç”¨çš„æ–¹å¼
            # æ ¹æ®è°ƒè¯•ä¿¡æ¯ï¼ŒGPT-5 Image ä½¿ç”¨ tool_calls æ¥ç”Ÿæˆå›¾ç‰‡
            use_tool_calls = is_gpt5_image
            
            # å¦‚æœæŒ‡å®šäº† aspect_ratio æˆ–è€…æ˜¯ GPT-5 Image æ¨¡å‹ï¼Œç›´æ¥ä½¿ç”¨ requests å‘é€è¯·æ±‚
            # ï¼ˆå› ä¸º OpenAI SDK å¯èƒ½ä¸æ”¯æŒ image_configï¼Œä¸” GPT-5 Image éœ€è¦ç‰¹æ®Šå‚æ•°ï¼‰
            if aspect_ratio or is_gpt5_image:
                import requests
                api_key = os.getenv("OPENROUTER_API_KEY", "").strip()
                headers = {
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://github.com/yourusername/tarot_agent",
                    "X-Title": "Tarot Agent"
                }
                
                payload = {
                    "model": self.model_id,
                    "messages": [
                        {"role": "user", "content": final_prompt}
                    ],
                    "modalities": ["image", "text"]
                }
                
                # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®ä¸åŒçš„å‚æ•°
                if is_gpt5_image:
                    # GPT-5 Image ç³»åˆ—ï¼šæ ¹æ® OpenRouter æ–‡æ¡£ï¼Œåº”è¯¥ä½¿ç”¨ image_config.aspect_ratio
                    # å‚è€ƒï¼šhttps://openrouter.ai/docs/features/multimodal/image-generation
                    # æ³¨æ„ï¼šGPT-5 Image å¯èƒ½ä¸æ”¯æŒç›´æ¥è®¾ç½® sizeï¼Œéœ€è¦é€šè¿‡ aspect_ratio
                    if aspect_ratio == "2:3":
                        # ä½¿ç”¨ aspect_ratio å‚æ•°ï¼ˆOpenRouter æ¨èæ–¹å¼ï¼‰
                        payload["image_config"] = {
                            "aspect_ratio": "2:3"
                        }
                        # åŒæ—¶å°è¯•åœ¨ prompt ä¸­æ˜ç¡®æŒ‡å®šï¼ˆå·²åœ¨ä¸Šé¢æ·»åŠ ï¼‰
                    elif aspect_ratio == "3:2":
                        payload["image_config"] = {
                            "aspect_ratio": "3:2"
                        }
                    else:
                        # å…¶ä»–æ¯”ä¾‹ï¼Œä½¿ç”¨ aspect_ratio
                        payload["image_config"] = {
                            "aspect_ratio": aspect_ratio
                        }
                else:
                    # å…¶ä»–æ¨¡å‹ï¼ˆå¦‚ Geminiï¼‰ï¼šä½¿ç”¨ aspect_ratio
                    payload["image_config"] = {
                        "aspect_ratio": aspect_ratio
                    }
                
                response_obj = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=120
                )
                response_obj.raise_for_status()
                response_dict = response_obj.json()
                
                # è°ƒè¯•ï¼šæ‰“å°è¯·æ±‚å’Œå“åº”ç»“æ„ï¼ˆä»…åœ¨å‰å‡ æ¬¡è°ƒç”¨æ—¶ï¼Œç”¨äºè°ƒè¯•ï¼‰
                # å¯¹äº GPT-5 Image (é Mini)ï¼Œæ‰“å°å®Œæ•´å“åº”ä»¥ä¾¿è°ƒè¯•
                if is_gpt5_image and "mini" not in self.model_id.lower():
                    debug_key = f'_debug_printed_{self.model_id}'
                    if not hasattr(self, debug_key):
                        print(f"   [è°ƒè¯•] GPT-5 Image å“åº”ç»“æ„: {json.dumps(response_dict, indent=2, ensure_ascii=False)[:1000]}...")
                        setattr(self, debug_key, True)
                
                # å°†å“åº”è½¬æ¢ä¸ºç±»ä¼¼ OpenAI SDK çš„æ ¼å¼
                class MockMessage:
                    def __init__(self, content, images, tool_calls=None):
                        self.content = content
                        self.images = images
                        self.tool_calls = tool_calls
                
                class MockChoice:
                    def __init__(self, message):
                        self.message = message
                
                class MockResponse:
                    def __init__(self, choices):
                        self.choices = choices
                
                choices_data = response_dict.get("choices", [])
                if not choices_data:
                    raise Exception("å“åº”ä¸­æœªæ‰¾åˆ° choices")
                
                message_data = choices_data[0].get("message", {})
                images_data = message_data.get("images", [])
                tool_calls_data = message_data.get("tool_calls", [])
                
                # åˆ›å»ºæ¨¡æ‹Ÿçš„å“åº”å¯¹è±¡
                mock_message = MockMessage(
                    content=message_data.get("content", ""),
                    images=images_data,
                    tool_calls=tool_calls_data
                )
                mock_choice = MockChoice(mock_message)
                response = MockResponse([mock_choice])
            else:
                # æ²¡æœ‰æŒ‡å®š aspect_ratioï¼Œä½¿ç”¨ OpenAI SDK
                request_params = {
                    "model": self.model_id,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "modalities": ["image", "text"]
                }
                response = self.client.chat.completions.create(**request_params)
            
            message = response.choices[0].message
            
            # æ£€æŸ¥å“åº”æ ¼å¼
            image_data_url = None
            
            # å¤„ç†ä½¿ç”¨ requests æ—¶çš„å“åº”ï¼ˆimages æ˜¯å­—å…¸åˆ—è¡¨ï¼‰
            if hasattr(message, 'images') and message.images:
                image_obj = message.images[0]
                if isinstance(image_obj, dict):
                    image_data_url = image_obj.get('image_url', {}).get('url', '')
                elif hasattr(image_obj, 'image_url'):
                    if isinstance(image_obj.image_url, dict):
                        image_data_url = image_obj.image_url.get('url', '')
                    else:
                        image_data_url = image_obj.image_url.url
                else:
                    raise Exception(f"æœªçŸ¥çš„å›¾ç‰‡æ ¼å¼: {type(image_obj)}")
            
            # å¤„ç† OpenAI SDK çš„å“åº”æ ¼å¼
            elif hasattr(message, 'content') and isinstance(message.content, list):
                for item in message.content:
                    if hasattr(item, 'type') and item.type == 'image_url':
                        if hasattr(item, 'image_url'):
                            if isinstance(item.image_url, dict):
                                image_data_url = item.image_url.get('url', '')
                            else:
                                image_data_url = item.image_url.url
                        break
                if not image_data_url:
                    raise Exception("æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®")
            
            # å°è¯•ä»åŸå§‹å“åº”ä¸­æå–
            if not image_data_url:
                response_dict = response_dict if 'response_dict' in locals() else (response.model_dump() if hasattr(response, 'model_dump') else {})
                choices = response_dict.get('choices', [])
                if choices:
                    message_dict = choices[0].get('message', {})
                    images = message_dict.get('images', [])
                    if images:
                        image_data_url = images[0].get('image_url', {}).get('url', '')
                    else:
                        raise Exception("å“åº”ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®")
                else:
                    raise Exception("å“åº”æ ¼å¼å¼‚å¸¸")
            
            if not image_data_url:
                raise Exception("å›¾ç‰‡ URL ä¸ºç©º")
            
            return {
                "data_url": image_data_url,
                "type": "base64"
            }
        except Exception as e:
            raise Exception(f"OpenRouter ç”Ÿæˆå¤±è´¥: {e}")
    
    def download_image(self, image_data: Any, save_path: Path) -> bool:
        """ä¿å­˜ base64 å›¾ç‰‡"""
        data_url = image_data.get("data_url")
        if not data_url:
            return False
        
        # è§£æ data URL: data:image/png;base64,...
        if data_url.startswith("data:image"):
            header, encoded = data_url.split(",", 1)
            image_bytes = base64.b64decode(encoded)
            
            save_path.parent.mkdir(parents=True, exist_ok=True)
            with open(save_path, 'wb') as f:
                f.write(image_bytes)
            return True
        return False


def get_available_openrouter_models() -> List[Dict[str, str]]:
    """è·å– OpenRouter å¯ç”¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹"""
    api_key = os.getenv("OPENROUTER_API_KEY", "").strip()
    if not api_key:
        return []
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get("https://openrouter.ai/api/v1/models", headers=headers, timeout=30)
        if response.status_code != 200:
            return []
        
        models = response.json().get("data", [])
        image_models = []
        
        for model in models:
            arch = model.get("architecture", {})
            output_modalities = arch.get("output_modalities", [])
            if "image" in output_modalities:
                image_models.append({
                    "id": model.get("id"),
                    "name": model.get("name", model.get("id")),
                    "description": model.get("description", "")[:100]
                })
        
        return image_models
    except Exception as e:
        print(f"âš ï¸  è·å– OpenRouter æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []


def compare_models(
    prompt: str,
    models_to_test: List[str],
    output_dir: Path,
    aspect_ratio: Optional[str] = None,
    n: int = 1
):
    """
    å¯¹æ¯”ä¸åŒæ¨¡å‹çš„å›¾åƒç”Ÿæˆæ•ˆæœ
    
    Args:
        prompt: æµ‹è¯•ç”¨çš„ prompt
        models_to_test: è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ï¼Œæ ¼å¼: ["aliyun", "dalle3", "openrouter:model_id"]
        output_dir: è¾“å‡ºç›®å½•
        aspect_ratio: å›¾ç‰‡æ¯”ä¾‹ï¼ˆä»…å¯¹æ”¯æŒçš„ OpenRouter æ¨¡å‹æœ‰æ•ˆï¼‰ï¼Œä¾‹å¦‚ "3:2", "16:9" ç­‰
    """
    print("\n" + "="*60)
    print("å›¾åƒç”Ÿæˆæ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("="*60)
    print(f"\næµ‹è¯• Prompt:")
    print(f"{prompt[:200]}...")
    print(f"\nPrompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜ prompt åˆ°æ–‡ä»¶
    prompt_file = output_dir / "test_prompt.txt"
    with open(prompt_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    print(f"\nğŸ“ Prompt å·²ä¿å­˜åˆ°: {prompt_file}")
    
    results = []
    
    for model_spec in models_to_test:
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æ¨¡å‹: {model_spec}")
        print(f"{'='*60}")
        
        try:
            # åˆå§‹åŒ–ç”Ÿæˆå™¨
            if model_spec == "aliyun":
                generator = AliyunGenerator()
                model_name = "Aliyun_Wan2.5"
            elif model_spec.startswith("aliyun:"):
                # æ”¯æŒæŒ‡å®šé˜¿é‡Œäº‘æ¨¡å‹ï¼Œä¾‹å¦‚: aliyun:wan2.1-t2i-plus
                model_id = model_spec.split(":", 1)[1]
                generator = AliyunGenerator(model=model_id)
                model_name = f"Aliyun_{model_id.replace('-', '_').replace('.', '_')}"
            elif model_spec == "dalle3":
                generator = Dalle3Generator()
                model_name = "DALL-E_3"
            elif model_spec == "gpt-image-1" or model_spec == "gpt-image-1-mini":
                # ç›´æ¥ä½¿ç”¨ OpenAI API çš„ GPT-Image-1 ç³»åˆ—
                generator = GPTImageGenerator(model=model_spec)
                model_name = model_spec.replace("-", "_")
            elif model_spec == "gpt-5-image" or model_spec == "gpt-5-image-mini":
                # GPT-5 Image ç³»åˆ—ä½¿ç”¨ OpenAI Responses API
                # æ˜ å°„ï¼šgpt-5-image -> gpt-5, gpt-5-image-mini -> gpt-5-mini
                openai_model = "gpt-5" if model_spec == "gpt-5-image" else "gpt-5-mini"
                generator = GPT5ImageGenerator(model=openai_model)
                model_name = model_spec.replace("-", "_")
            elif model_spec.startswith("openrouter:"):
                model_id = model_spec.split(":", 1)[1]
                # å¦‚æœæ˜¯ GPT-5 Image ç³»åˆ—ï¼Œä½¿ç”¨ OpenAI API è€Œä¸æ˜¯ OpenRouter
                if model_id in ["openai/gpt-5-image", "openai/gpt-5-image-mini"]:
                    # æå–æ¨¡å‹åç§°å¹¶æ˜ å°„åˆ° OpenAI API æ¨¡å‹å
                    if "mini" in model_id:
                        openai_model = "gpt-5-mini"
                    else:
                        openai_model = "gpt-5"
                    generator = GPT5ImageGenerator(model=openai_model)
                    model_name = model_id.replace("/", "_").replace(":", "_").replace("openai_", "")
                else:
                    # å…¶ä»– OpenRouter æ¨¡å‹ï¼ˆå¦‚ Geminiï¼‰ç»§ç»­ä½¿ç”¨ OpenRouter
                    generator = OpenRouterImageGenerator(model_id)
                    model_name = model_id.replace("/", "_").replace(":", "_")
            else:
                print(f"âŒ æœªçŸ¥çš„æ¨¡å‹: {model_spec}")
                continue
            
            # ç”Ÿæˆå›¾ç‰‡
            print(f"ğŸ“¤ ç”Ÿæˆå›¾ç‰‡ä¸­...")
            if model_spec in ["gpt-image-1", "gpt-image-1-mini"]:
                print(f"   ä½¿ç”¨ OpenAI Images APIï¼Œé»˜è®¤å°ºå¯¸: 1024Ã—1536 (2:3 portrait)")
            elif model_spec in ["gpt-5-image", "gpt-5-image-mini"] or \
                 (model_spec.startswith("openrouter:") and "openai/gpt-5-image" in model_spec):
                print(f"   ä½¿ç”¨ OpenAI Responses APIï¼Œé»˜è®¤å°ºå¯¸: 1024Ã—1536 (2:3 portrait)")
            elif aspect_ratio and model_spec.startswith("openrouter:"):
                print(f"   ä½¿ç”¨å›¾ç‰‡æ¯”ä¾‹: {aspect_ratio}")
            start_time = time.time()
            if aspect_ratio and model_spec.startswith("openrouter:") and "openai/gpt-5-image" not in model_spec:
                # OpenRouter æ¨¡å‹ï¼ˆé GPT-5 Imageï¼‰ï¼Œä½¿ç”¨ aspect_ratio
                image_data = generator.generate_image(prompt, aspect_ratio=aspect_ratio, n=n)
            elif model_spec in ["gpt-image-1", "gpt-image-1-mini"]:
                # GPT-Image-1 ç³»åˆ—é»˜è®¤ä½¿ç”¨ 1024x1536 (2:3 ç«–å±)
                if aspect_ratio == "2:3" or aspect_ratio is None:
                    size = "1024x1536"  # 2:3 ç«–å±
                elif aspect_ratio == "3:2":
                    size = "1536x1024"  # 3:2 æ¨ªå±ï¼ˆæ³¨æ„ï¼šè¿™æ˜¯æ¨ªå±ï¼Œä¸æ˜¯ç«–å±ï¼‰
                else:
                    size = "1024x1536"  # é»˜è®¤ç«–å±
                image_data = generator.generate_image(prompt, size=size, n=n)
            elif model_spec in ["gpt-5-image", "gpt-5-image-mini"] or \
                 (model_spec.startswith("openrouter:") and "openai/gpt-5-image" in model_spec):
                # GPT-5 Image ç³»åˆ—ä½¿ç”¨ Responses APIï¼Œé»˜è®¤ä½¿ç”¨ 1024x1536 (2:3 ç«–å±)
                if aspect_ratio == "2:3" or aspect_ratio is None:
                    size = "1024x1536"  # 2:3 ç«–å±
                elif aspect_ratio == "3:2":
                    size = "1536x1024"  # 3:2 æ¨ªå±ï¼ˆæ³¨æ„ï¼šè¿™æ˜¯æ¨ªå±ï¼Œä¸æ˜¯ç«–å±ï¼‰
                else:
                    size = "1024x1536"  # é»˜è®¤ç«–å±
                image_data = generator.generate_image(prompt, size=size, n=n)
            elif model_spec == "dalle3":
                # DALL-E 3 åªæ”¯æŒ n=1ï¼Œå¦‚æœ n > 1 ä¼šå¤šæ¬¡è°ƒç”¨ API
                image_data = generator.generate_image(prompt, n=n)
            else:
                image_data = generator.generate_image(prompt, n=n)
            elapsed_time = time.time() - start_time
            
            # ä¿å­˜å›¾ç‰‡
            safe_model_name = model_name.replace(" ", "_").replace("/", "_")
            save_path = output_dir / f"{safe_model_name}.png"
            
            print(f"ğŸ’¾ ä¿å­˜å›¾ç‰‡åˆ°: {save_path.name}")
            success = generator.download_image(image_data, save_path)
            
            if success:
                # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†å¤šå¼ å›¾ç‰‡
                if image_data.get("type") in ["base64_multiple", "url_multiple"]:
                    count = image_data.get("count", 1)
                    print(f"âœ… æˆåŠŸç”Ÿæˆ {count} å¼ å›¾ç‰‡ï¼")
                    print(f"   è€—æ—¶: {elapsed_time:.1f} ç§’")
                    # è®¡ç®—æ‰€æœ‰å›¾ç‰‡çš„æ€»å¤§å°
                    total_size = 0
                    base_name = save_path.stem
                    extension = save_path.suffix
                    file_paths = []
                    for i in range(count):
                        if count > 1:
                            multi_path = save_path.parent / f"{base_name}_{i+1}{extension}"
                        else:
                            multi_path = save_path
                        if multi_path.exists():
                            total_size += multi_path.stat().st_size
                            file_paths.append(str(multi_path))
                    print(f"   æ€»æ–‡ä»¶å¤§å°: {total_size / 1024:.2f} KB")
                    
                    results.append({
                        "model": model_spec,
                        "model_name": model_name,
                        "success": True,
                        "time": elapsed_time,
                        "file_size": total_size,
                        "file_path": str(save_path),
                        "image_count": count,
                        "file_paths": file_paths
                    })
                else:
                    file_size = save_path.stat().st_size
                    print(f"âœ… æˆåŠŸï¼")
                    print(f"   è€—æ—¶: {elapsed_time:.1f} ç§’")
                    print(f"   æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB")
                    
                    results.append({
                        "model": model_spec,
                        "model_name": model_name,
                        "success": True,
                        "time": elapsed_time,
                        "file_size": file_size,
                        "file_path": str(save_path)
                    })
            else:
                print(f"âŒ ä¿å­˜å¤±è´¥")
                results.append({
                    "model": model_spec,
                    "model_name": model_name,
                    "success": False,
                    "error": "ä¿å­˜å¤±è´¥"
                })
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(2)
        
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results.append({
                "model": model_spec,
                "model_name": model_spec,
                "success": False,
                "error": str(e)
            })
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    results_file = output_dir / "comparison_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            "prompt": prompt,
            "test_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "results": results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\n{'='*60}")
    print("å¯¹æ¯”æµ‹è¯•å®Œæˆ")
    print(f"{'='*60}")
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    success_count = sum(1 for r in results if r.get("success"))
    print(f"   æˆåŠŸ: {success_count}/{len(results)}")
    print(f"   å¤±è´¥: {len(results) - success_count}/{len(results)}")
    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"   - å›¾ç‰‡æ–‡ä»¶: {output_dir}/*.png")
    print(f"   - å¯¹æ¯”ç»“æœ: {results_file}")
    print(f"{'='*60}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="å›¾åƒç”Ÿæˆæ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    parser.add_argument("--prompt", type=str, help="æµ‹è¯•ç”¨çš„ promptï¼ˆå¦‚æœä¸æä¾›ï¼Œå°†ä½¿ç”¨é»˜è®¤çš„å¡”ç½—ç‰Œæè¿°ï¼‰")
    parser.add_argument("--models", type=str, nargs="+", 
                       help="è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ï¼Œä¾‹å¦‚: aliyun dalle3 gpt-image-1-mini gpt-image-1 openrouter:google/gemini-2.5-flash-image-preview")
    parser.add_argument("--list-openrouter", action="store_true", help="åˆ—å‡º OpenRouter å¯ç”¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹")
    parser.add_argument("--output", type=str, default=None, help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: database/images/comparison_YYYYMMDD_HHMMSSï¼‰")
    parser.add_argument("--aspect-ratio", type=str, default=None,
                       help="å›¾ç‰‡æ¯”ä¾‹ï¼Œä¾‹å¦‚: 2:3 (ç«–å±), 3:2 (æ¨ªå±), 16:9, 1:1 ç­‰ã€‚å¯¹äº GPT-Image-1 ç³»åˆ—ï¼Œæ”¯æŒ 2:3 (1024x1536) å’Œ 3:2 (1536x1024)")
    parser.add_argument("--n", type=int, default=1,
                       help="æ¯ä¸ªæ¨¡å‹ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡ï¼ˆé»˜è®¤: 1ï¼Œæœ€å¤§: 10ï¼‰")
    
    args = parser.parse_args()
    
    # åˆ—å‡º OpenRouter æ¨¡å‹
    if args.list_openrouter:
        print("\næŸ¥è¯¢ OpenRouter å¯ç”¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹...")
        models = get_available_openrouter_models()
        if models:
            print(f"\næ‰¾åˆ° {len(models)} ä¸ªæ”¯æŒå›¾åƒç”Ÿæˆçš„æ¨¡å‹:\n")
            for i, model in enumerate(models, 1):
                print(f"{i}. {model['id']}")
                print(f"   åç§°: {model['name']}")
                print(f"   æè¿°: {model['description']}")
                print()
        else:
            print("æœªæ‰¾åˆ°å¯ç”¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œè¯·æ£€æŸ¥ OPENROUTER_API_KEY æ˜¯å¦æ­£ç¡®è®¾ç½®")
        sys.exit(0)
    
    # å‡†å¤‡ prompt
    if args.prompt:
        test_prompt = args.prompt
    else:
        # ä½¿ç”¨ç¬¬ä¸€å¼ å¡”ç½—ç‰Œçš„æè¿° + é£æ ¼æè¿°
        json_path = project_root / "database" / "data" / "pkt_tarot_cards.json"
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                cards = json.load(f)
            description = cards[0].get("description", "")
            # æ¨èä½¿ç”¨çš„è¯¦ç»†ç‰ˆ style_prompt
            style_prompt = "Tarot card illustration in a highly abstract, mystical, and fantastical 2D art style. Features stylized and symbolic figures, avoiding any realistic human features. The scene is imbued with a surreal, dreamlike quality and a magical, arcane atmosphere. The composition seamlessly fuses geometric patterns, esoteric symbols, and otherworldly elements, while maintaining a moderate complexity and a clear, balanced structure. Use minimal yet dramatic lighting to create an ethereal glow. The emphasis is on symbolic representation to evoke a sense of wonder, fantasy, and profound mystery."
            test_prompt = f"{description} {style_prompt}"
        else:
            test_prompt = "A mysterious, abstract, dark 2D artwork with fantastical elements, featuring abstract symbolic human forms, occult atmosphere, and mystical symbols"
    
    # å‡†å¤‡è¦æµ‹è¯•çš„æ¨¡å‹
    if args.models:
        models_to_test = args.models
    else:
        # é»˜è®¤æµ‹è¯•åˆ—è¡¨ï¼šåŒ…å«æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
        models_to_test = []
        
        # æ·»åŠ é˜¿é‡Œäº‘æ¨¡å‹
        if os.getenv("ALIYUN_DASHSCOPE_API_KEY"):
            # é»˜è®¤ä½¿ç”¨ wan2.5-t2i-preview
            models_to_test.append("aliyun")
            # å¯é€‰ï¼šæ·»åŠ å…¶ä»–é˜¿é‡Œäº‘æ¨¡å‹è¿›è¡Œå¯¹æ¯”
            # models_to_test.append("aliyun:wan2.1-t2i-turbo")
            # models_to_test.append("aliyun:wan2.1-t2i-plus")
        
        # æ·»åŠ  DALL-E 3
        if os.getenv("OPENAI_API_KEY"):
            models_to_test.append("dalle3")
            # æ·»åŠ  GPT-Image-1 ç³»åˆ—ï¼ˆç›´æ¥ä½¿ç”¨ OpenAI APIï¼‰
            models_to_test.append("gpt-image-1-mini")
            models_to_test.append("gpt-image-1")
        
        # æ·»åŠ æ‰€æœ‰å¯ç”¨çš„ OpenRouter æ–‡ç”Ÿå›¾æ¨¡å‹
        if os.getenv("OPENROUTER_API_KEY"):
            openrouter_models = get_available_openrouter_models()
            if openrouter_models:
                print(f"\næ‰¾åˆ° {len(openrouter_models)} ä¸ª OpenRouter æ–‡ç”Ÿå›¾æ¨¡å‹ï¼Œå°†å…¨éƒ¨åŠ å…¥å¯¹æ¯”æµ‹è¯•")
                for model in openrouter_models:
                    models_to_test.append(f"openrouter:{model['id']}")
            else:
                print("\nâš ï¸  æœªæ‰¾åˆ° OpenRouter æ–‡ç”Ÿå›¾æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®")
        
        if not models_to_test:
            print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡å‹")
            print("   è¯·è‡³å°‘è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä¹‹ä¸€:")
            print("   - ALIYUN_DASHSCOPE_API_KEY (é˜¿é‡Œäº‘)")
            print("   - OPENAI_API_KEY (DALL-E 3)")
            print("   - OPENROUTER_API_KEY (OpenRouter)")
            sys.exit(1)
    
    # å‡†å¤‡è¾“å‡ºç›®å½•
    if args.output:
        output_dir = Path(args.output)
    else:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_dir = project_root / "database" / "images" / f"comparison_{timestamp}"
    
    # è¿è¡Œå¯¹æ¯”æµ‹è¯•
    n = max(1, min(args.n, 10))  # é™åˆ¶åœ¨ 1-10 ä¹‹é—´
    if args.n != n:
        print(f"âš ï¸  è­¦å‘Š: n å‚æ•°å·²è°ƒæ•´ä¸º {n}ï¼ˆå¿…é¡»åœ¨ 1-10 ä¹‹é—´ï¼‰")
    compare_models(test_prompt, models_to_test, output_dir, aspect_ratio=args.aspect_ratio, n=n)

